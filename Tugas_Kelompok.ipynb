{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch sastrawi googletrans==4.0.0-rc1 vaderSentiment nltk google-api-python-client textblob datasets pandas imbalanced-learn nlpaug bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEfFqf_n5h60",
        "outputId": "83524094-4ca0-4ecb-baba-fe70cbf4ec5f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.7.4)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.16.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from googletrans import Translator\n",
        "from googleapiclient.discovery import build\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import torch\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import nlpaug.augmenter.word as naw\n",
        "from bert_score import score\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEAAO52_5o2D",
        "outputId": "c7bb6f7f-fdb6-4500-8165-da34c1e2bb49"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/kamusnormalisasi.xlsx'\n",
        "kamus_normalisasi = pd.read_excel(file_path)\n",
        "normalization_dict = pd.Series(kamus_normalisasi.formal.values, index=kamus_normalisasi.slang).to_dict()"
      ],
      "metadata": {
        "id": "d0nCelFE5so8"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'AIzaSyAAPg5vLDAON71Wqpl7x-xslcNVI5o_IRA'\n",
        "query = '#Polri'\n",
        "max_videos = 100\n",
        "max_comments_per_video = 50\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "def search_videos(query, max_results):\n",
        "    request = youtube.search().list(\n",
        "        part=\"id\",\n",
        "        q=query,\n",
        "        type=\"video\",\n",
        "        maxResults=max_results\n",
        "    )\n",
        "    response = request.execute()\n",
        "    video_ids = [item['id']['videoId'] for item in response['items']]\n",
        "    return video_ids\n",
        "\n",
        "def get_comments(video_id, max_results):\n",
        "    comments = []\n",
        "    request = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        maxResults=max_results,\n",
        "        textFormat=\"plainText\"\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    while request is not None and len(comments) < max_results:\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            comments.append(comment)\n",
        "            if len(comments) >= max_results:\n",
        "                break\n",
        "        if 'nextPageToken' in response and len(comments) < max_results:\n",
        "            request = youtube.commentThreads().list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video_id,\n",
        "                pageToken=response['nextPageToken'],\n",
        "                maxResults=max_results,\n",
        "                textFormat=\"plainText\"\n",
        "            )\n",
        "            response = request.execute()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "print(\"Fetching videos...\")\n",
        "video_ids = search_videos(query, max_videos)\n",
        "print(\"Video IDs:\", video_ids)\n",
        "\n",
        "print(\"Fetching comments...\")\n",
        "all_comments = []\n",
        "for video_id in video_ids:\n",
        "    comments = get_comments(video_id, max_comments_per_video)\n",
        "    all_comments.extend(comments)\n",
        "print(\"Total comments fetched:\", len(all_comments))\n",
        "\n",
        "print(\"Creating DataFrame...\")\n",
        "df = pd.DataFrame(all_comments, columns=['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC95qg9P5xJU",
        "outputId": "fc5a0cc0-b040-452c-ec3e-89ea172a08f4"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching videos...\n",
            "Video IDs: ['DBEVN5ZP_OI', 'Rz2BGdoIsk8', 'qg9cokplNU4', '5T0Wb1w5-vw', '5HtGhaW1T6c', '-pCt-MzwMcs', 'j6CL7A9XLn8', 'QSyFdDLrni4', 'tOFrw7arNI0', '9p47P9XyunY', 'cUN-m7bGDGk', 'JFrrX6VN5UI', 'Vossp_DCKBc', 'NdRk5NblWW4', 'jdBUob5ecuw', 'HE6jXQBDElk', 'h1k4RPVv1FM', 'r7bmtnDKIJ8', 'UPDtkz6dTfQ', '9WWHimuLPjI', '6mGmlsS4gn0', 'rD4NUmuvTAE', 'tBmw0n-bxJU', '_Esc0VKAYcY', '8rwle35j3X8', 'KRm_aeMGS2w', 'Ny_pi3946WM', 'nwMpDUDop94', '45EKsmrj0qI', 'QuyuYDsXZ6Q', 'i4irvXUwU6g', 'qenxWtEEOQc', 'dh0uGaF_ylw', '8FzUA8TfMLg', '27PSdXrrTa8', 'tM4TSW5hMuo', '5paYSv_VDtg', 'v_9r7c8X-mQ', '5rx6ZdBK05Y', 'wcrqfi29nf4', 'Y3D6674LdFs', 'g4RThmEvVmw', 'mWLTtpxI9fg', 'p5R_dQ1xPP0', '1XQdRGpvJ6g', '1bRvTnLlH3w', '4WiHmdwFHno', 'qxAsf419TLs', 'yrFLnwo-BMw', 'vW_W8HBKi2Q']\n",
            "Fetching comments...\n",
            "Total comments fetched: 2096\n",
            "Creating DataFrame...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, normalization_dict):\n",
        "    text = clean_text(text)\n",
        "    text = case_folding(text)\n",
        "    tokens = tokenize(text)\n",
        "    tokens = normalize(tokens, normalization_dict)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = stemming(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def case_folding(text):\n",
        "    return text.lower()\n",
        "\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def normalize(tokens, normalization_dict):\n",
        "    return [normalization_dict.get(token, token) for token in tokens]\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('indonesian'))\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def stemming(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "print(\"Preprocessing comments...\")\n",
        "df['cleaned_text'] = df['text'].apply(lambda x: preprocess(x, normalization_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0d6r-yM6DJb",
        "outputId": "48db2f1f-0c99-4e4c-816b-577bf9f293a8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing comments...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_pipeline = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "def get_sentiment_label(text):\n",
        "    result = sentiment_pipeline(text)[0]\n",
        "    if result['label'] in ['4 stars', '5 stars']:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['sentiment'] = df['cleaned_text'].apply(get_sentiment_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu-w-dFv7vIk",
        "outputId": "9c5ea6c0-0f73-402b-c2f4-d78733fe2aa1"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug = naw.SynonymAug(aug_src='wordnet')\n",
        "\n",
        "def augment_texts(texts, labels, target_label, n_augmentations=5):\n",
        "    augmented_texts = []\n",
        "    augmented_labels = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        if label == target_label:\n",
        "            for _ in range(n_augmentations):\n",
        "                augmented_text = aug.augment(text)\n",
        "                augmented_texts.append(augmented_text)\n",
        "                augmented_labels.append(label)\n",
        "    return augmented_texts, augmented_labels\n",
        "\n",
        "positive_texts, positive_labels = augment_texts(df['cleaned_text'].tolist(), df['sentiment'].tolist(), target_label=1)\n",
        "\n",
        "augmented_texts = df['cleaned_text'].tolist() + positive_texts\n",
        "augmented_labels = df['sentiment'].tolist() + positive_labels"
      ],
      "metadata": {
        "id": "j7wHiIdy70v3"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "texts_resampled, labels_resampled = ros.fit_resample(pd.DataFrame(augmented_texts, columns=['text']), pd.Series(augmented_labels, name='label'))\n",
        "\n",
        "texts_resampled = texts_resampled['text'].tolist()\n",
        "labels_resampled = labels_resampled.tolist()"
      ],
      "metadata": {
        "id": "_C4xzqIR8xTM"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CommentsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "model_name = \"indobenchmark/indobert-base-p1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "dataset = CommentsDataset(texts_resampled, labels_resampled, tokenizer, max_len=128)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WvVeYFHb8z-Z",
        "outputId": "2b391674-ea07-4f89-d344-35adf94c9ec6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2034' max='2034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2034/2034 04:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.657900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.507300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.384200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.240200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.351500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.198400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.178100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.303700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.215800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.169700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.307900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.245700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.358600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.222000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.230200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.185200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.264000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.240400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.133400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.178700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.197300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.478600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.447900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.212100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.149200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.092400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.449500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.198600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.227600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.149000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.240700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.124400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.271300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.197700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.182500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.217200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.189300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.161700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.336500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.381500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.231200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.214400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.128700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.225300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.428300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.335700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.197300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.234100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.207200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.212800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.306400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.236900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.184000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.246000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.365700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.150400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.332900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.378600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.198700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.226600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.370200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.329400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.249400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.252500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.118100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.278200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.303500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.426400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.172100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.192200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.292300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.172700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.148900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.278900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.315900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.245200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.279700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.213000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.161400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.396000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.299900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.288300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.183900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.113000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.483200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.251300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.269300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.313800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.108600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.295300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.189600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.272500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.320200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.158800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.063900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.384100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.234300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.304800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.099000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.420900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.274200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.191100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.283500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.238600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.290700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.199500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.252300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.343500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.114400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.159000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.174700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.092100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.182700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.159900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.052900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.250300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.266300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.517500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.045100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.091700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.196100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.176400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.040800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.181200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.175600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.133400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.158200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.206200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.186600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.301100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.240300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.229700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.295800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.220800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.044200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.141700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.193000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.117600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.091900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.105900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.157100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.052100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.253800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.175600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.180200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.243300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.103100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.118900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.056300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.240200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.158400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.193800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.237000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.155600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.148300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.047000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.272800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.234400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.109900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.251700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>0.264900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>0.058900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>0.206300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2034, training_loss=0.2132133335505146, metrics={'train_runtime': 294.0749, 'train_samples_per_second': 55.333, 'train_steps_per_second': 6.917, 'total_flos': 1070335773204480.0, 'train_loss': 0.2132133335505146, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = torch.tensor(predictions.predictions).argmax(dim=1).numpy()\n",
        "\n",
        "y_test = [item['labels'].item() for item in test_dataset]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred_labels))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, pred_labels, target_names=['negative', 'positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "19gnyX7s89_Y",
        "outputId": "4518e2f5-9468-4642-cd97-427c1d8fd184"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9513274336283186\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.92      0.99      0.95       677\n",
            "    positive       0.99      0.91      0.95       679\n",
            "\n",
            "    accuracy                           0.95      1356\n",
            "   macro avg       0.95      0.95      0.95      1356\n",
            "weighted avg       0.95      0.95      0.95      1356\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_tensors(tensors, tokenizer):\n",
        "    return [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in tensors]\n",
        "\n",
        "test_texts = [dataset[i]['input_ids'].tolist() for i in test_dataset.indices]\n",
        "decoded_texts = decode_tensors(test_texts, tokenizer)\n",
        "\n",
        "filtered_decoded_texts = [text for text in decoded_texts if text.strip()]\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'text': filtered_decoded_texts,\n",
        "    'predicted_sentiment': pred_labels[:len(filtered_decoded_texts)]\n",
        "})\n",
        "\n",
        "test_df['predicted_sentiment'] = test_df['predicted_sentiment'].apply(lambda x: 'positive' if x == 1 else 'negative')"
      ],
      "metadata": {
        "id": "1c2GAzf--I8J"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_counts = test_df['predicted_sentiment'].value_counts()\n",
        "sentiment_counts.plot(kind='bar', color=['blue', 'red'])\n",
        "plt.title('Sentiment Analysis of YouTube Comments')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "test_df.to_csv('Hasil.csv', index=False)\n",
        "print(\"Hasil berhasil disimpan dalam file 'Hasil.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "U6SjXoTq-RMZ",
        "outputId": "6b4384d7-67df-4ed6-e0b5-dd5ed3cca7db"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil berhasil disimpan dalam file 'Hasil.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references = test_df['text'].tolist()\n",
        "candidates = test_df['predicted_sentiment'].tolist()\n",
        "\n",
        "P, R, F1 = score(candidates, references, lang='en', model_type='bert-base-multilingual-cased')\n",
        "\n",
        "print(f\"BERTScore Precision: {P.mean().item():.4f}\")\n",
        "print(f\"BERTScore Recall: {R.mean().item():.4f}\")\n",
        "print(f\"BERTScore F1: {F1.mean().item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etaXwlJo-WXQ",
        "outputId": "fdd850af-e54e-4006-b462-b982af6f3b1c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.6805\n",
            "BERTScore Recall: 0.5733\n",
            "BERTScore F1: 0.6213\n"
          ]
        }
      ]
    }
  ]
}